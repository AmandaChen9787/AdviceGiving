---
title: "Flattering Advice: Avoiding Disappointment as a Driver of Gender Discrimination"
shorttitle        : "Flattering Advice"
author: 
  - name          : "Amanda Chen"
    affiliation   : "1"
    corresponding : yes    
    email         : "zchengj@connect.ust.hk"
    address       : "Department of Management, The Hong Kong University of Science and Technology, Hong Kong"
  - name          : "David Hagmann"
    affiliation   : "1"
affiliation:
  - id            : "1"
    institution   : "The Hong Kong University of Science and Technology"
note : |
  `r format(Sys.time(), "%e %B, %Y")`
abstract: |
  The purpose of advice is to help recipients make better decisions and solve their problems. However, in this paper, we propose that advisors may also take recipients' responses into account and attempt to avoid disappointing them, leading to what we call "flattering advice." In two pre-registered experiments involving real interactions between advisors and advisees (n = 2,700), we show that individuals consider others' expectations when giving advice, even when such expectations do not provide informative insights for the underlying decision-making problem. As a result, men receive more aspirational advice than women, given their higher confidence, when expectations (but not gender) are shown to advisors. However, incorporating expectations leads to worse outcomes (Study 1). Individuals inflate their advice due to interpersonal considerations: people who are concerned about advisees' likability inflate their advice to a great extent. Advisees reward such flattering advice, finding the advisers more likable and no less trustworthy than those who provide more accurate advice (Study 2). We discuss practical and theoretical contributions and future research directions.
keywords          : "Gender difference, Advice, Interpresonal relationship"
wordcount         : "4,362"
figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no
documentclass     : "apa7"
csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
classoption       : "man"
header-includes:
   - \usepackage{setspace, appendix, placeins, booktabs, tikz, siunitx}
   - \usepackage{tabularx, epigraph, float, colortbl, tabu, pdflscape}
   - \usetikzlibrary{positioning}
   - \raggedbottom
   - \usepackage[maxfloats=256]{morefloats}
   - \maxdeadcycles=1000
bibliography      : bibliography.bib
output: 
  # papaja::apa6_docx
  papaja::apa6_pdf
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
always_allow_html: true
---

```{r setup, include=FALSE}
library(magrittr)

knitr::opts_chunk$set(fig.width = 8, fig.height = 4, cache = F, echo = F,
                      fig.align = 'center',warning = FALSE, message = FALSE)

study1_math50 <- read.csv(here::here("Data/Cleaned Data/S1_Math50_cleaned.csv"))
study1_time1All <- readRDS(here::here("Data/Study1_time1All.Rds"))
study1_time1 <- readRDS(here::here("Data/Study1_time1.Rds"))
study1_time2_giver <- readRDS(here::here("Data/Study1_time2_giver.Rds"))
study1_time2_giver50 <- readRDS(here::here("Data/Study1_time2_giver50.Rds"))
study1_advice <- readRDS(here::here("Data/Study1_time2_advice.Rds"))
study1_time3 <- readRDS(here::here("Data/Study1_time3.Rds"))

```

# Introduction

Seeking and giving advice can present conversational challenges that
are difficult to navigate. Advice seekers may be embarrassed to ask for
help [@Benabou2022], and they may fail to do so if the information they
receive could lead to disappointment [@Gill2012]. Indeed, people prefer
advisers who withhold unpleasant information [@Shalvi2019] and punish
those who tell them things they do not want to hear [@John2019]. People
appear to engage in strategic selection of advice to avoid unpleasant
information and protect the utility they get from positive beliefs about
themselves and the future they anticipate [@Loewenstein2018;
@Loewenstein1987]. But do advice givers anticipate and consider the
hedonic cost of honest information to the recipient? While previous work
has emphasized the instrumental value of advice (e.g., satisfaction with
a decision or accuracy of a prediction), we focus on the motivations of
the person providing advice.

Research on advice has largely focused on settings that do not tackle
belief utility. For example, participants may have been asked to
estimate the number of balls in an urn or choose from pairs of lotteries
[@Benjamin2015]. Advisers have been shown to be motivated to give
accurate advice [@Jonas2003], and engage in perspective-taking to meet
the preferences of the advisee [@Kray2000; @Kray1999]. When they are
uncertain, they even prefer that advisees do not rely (extensively) on their
recommendations [@Ache2020]. Thus, it seems that people are concerned
about providing good advice even when they are not incentivized for the
recipient's decision quality.

In many real settings, however, advice incorporates beliefs about the
recipient. Someone recommending an expensive restaurant conveys that
they think the advisee is wealthy enough to afford an expensive meal,
and someone recommending a student pursue a PhD in economics assumes
that they are intellectually capable. Conversely, telling a poorly
performing student to switch to a less-demanding major conveys a belief
that the student is not capable of improving. Thus, while the painful truth
may prevent someone from making a bad decision, it may come at a hedonic cost to
the recipient and damage the relationship between the adviser and
advisee. We propose that advisers take these costs into account, even
when the interactions are entirely anonymous and they are incentivized
for the quality of the advisee's decision.

Specifically, we focus on the signaling value of advice: what does the
advice imply about the adviser's perception of the advisee? We propose
that advisees have expectations about the advice they receive and treat
this as a reference point [@Koszegi2006]. Advice that falls short of
these expectations creates disappointment, while advice that exceeds
them is flattering and creates positive interpersonal benefits because
it creates a perception that the adviser holds the advisee in high
esteem. Such interpersonal considerations may be as important, if not
more important, to the adviser than the instrumental value of the
advice: the adviser directly experiences a souring relationship, but may
suffer little and only much delayed consequences if an advisee makes a
poor life decision.

Our account therefore predicts that people give and receive advice that is more
flattering and suggestive of inflated ability and optimistic outcomes
than would advice in the absence of such interpersonal considerations.
However, we propose that this is not true for all advisees equally.
Presenting flattering advice requires the formation of beliefs about the
advisee's expectations (reference point). @Exley2022 show that men are
more overconfident than women, conditional on equal performance, and that
people anticipate this difference. An adviser who seeks to avoid disappointment and incorporates
expectations into their advice would then present more favorable advice
to male advisees than to female advisees (see Figure 1 for an
illustration). This provides a novel account for a well-known finding
that men receive more aspirational advice than do women [@Kanze2018].
Notably, when it pays to have accurate beliefs, such flattering advice
would come at a cost: while men would be more likely to aim higher, they
would also suffer greater costs from aiming too high and failing to meet
the objective.

In a large, preregistered experiment (n = 2,000), we show that advisers
consider the expectations of advisees, even when such expectations do
not provide informative insights for the underlying decision-making
problem. We find that as a result, showing expectations (but not gender)
to advisers leads men to receive more aspirational advice than women.
Incorporating expectations leads to worse advice, even when advisers are
incentivized based on the outcome of the advisee's decision. In a second
preregistered experiment (n = 700), we show that advisers respond to incentives for
interpersonal considerations. They tell people that they are more
attractive than they believe them to be, and inflate to a greater extent
when incentivized for likability rather than accuracy. Notably, they inflate
even when only incentivized for accuracy. Advisees indeed
reward such flattering advice, rating the advisers more likeable and no
less trustworthy than those who provide more accurate advice.

# Open Science Statement

We report all sample sizes, data exclusions, manipulations, and
measures in the studies. Screen captures of the experimental materials
are available in the Supplemental Information. The complete data, code
to reproduce all statistical analyses and figures in the manuscript, as
well as the preregistration reports are available via OSF. All our
studies were preregistered on AsPredicted.org.^[<https://osf.io/8r3d4/?view_only=5ad7bafcd16b4d4ba08bb28b0e2bd02d>]

# Study 1

We begin by examining whether advisers take the expectations of advisees
into account, even when those expectations are not relevant to the decision
the advisee has to make. In a three-stage experiment, we first recruit a
sample of advisees and ask them to complete a mathematics quiz. After
answering ten multiple-choice questions, participants are anchored
to low or high performance expectations and asked to guess how many
questions they answered correctly. Next, we recruit advisers and
show them either only the true performance of the advisee, or the true
performance and how many questions they guessed they answered correctly.
Advisers are tasked with recommending whether the advisee should compete
against a group of high-performers or a group of low-performers on the
mathematics quiz, where a potential bonus depends on outperforming the competitor
and which group was chosen. Finally, we invite the advisees back and show them the
advice they have received. Advisees then pick whether to compete against
high or low performers, with the outcome determined by their past performance on the quiz. Our
key hypotheses are that (1) advisees who were anchored to high expectations
would be more likely to receive advice to compete against the high
performer group, and (2) that men are more likely than women to be advised to 
compete against the high-performer group when expectations are shown.

## Methods

```{r}

subgroup_averages <- data.frame(subgroup = numeric(), avg_score = numeric())
set.seed(807)
# loop through 1000 iterations of randomly selecting 10 participants and computing their average score
for (i in 1:1000) {
  # randomly select 10 participants
  subgroup <- sample(study1_math50$ProlificID, size = 5, replace = FALSE)
  # compute the average score for the selected participants
  subgroup_avg <- mean(study1_math50$Score[study1_math50$ProlificID %in% subgroup])
  # add the subgroup and its average score to the dataframe
  subgroup_averages <- rbind(subgroup_averages, data.frame(subgroup = i, avg_score = subgroup_avg))
}

p5 <- quantile(subgroup_averages$avg_score, probs = 0.05)
p95 <- quantile(subgroup_averages$avg_score, probs = 0.95)

sortedScore <- sort(study1_math50$Score, decreasing = TRUE)
LP_lower <- sortedScore[50]
LP_upper <- sortedScore[31]
HP_lower <- sortedScore[20]
HP_upper <- sortedScore[1]

```

As part of our main experiment, participants choose to compete against a group
of previous participants and have their expectations anchored based on their performance.
Thus, we begin by first recruiting a sample of `r scales::comma(dim(study1_math50)[1])`
participants from Prolific to complete a 10-question multiple choice
mathematics quiz. The questions were taken from a paper-version of the
ASVAB standardized exam, such that answers were not available online.
Participants had five minutes to answer the quiz and were paid 10 cents for
each correctly answered question. We define the top 20 scorers as the
"High Performers" and the bottom 20 scorers as the "Low Performers." On
average, participants answered `r round(mean(study1_math50$Score),2)`
questions correctly, High Performers scored between `r HP_lower` and
`r HP_upper`, and Low Performers scored between `r LP_lower` and
`r LP_upper`. In order to anchor the expectations of participants in our main
experiment, we simulated 1,000 pairings of groups of five
participants, with the 5<sup>th</sup> percentile of groups scoring an average of
`r p5` and the 95 th percentile scoring an average of `r p95`. We report these
averages to participants in the Low Expectations and High Expectations treatment,
respectively.

We then recruited `r scales::comma(dim(study1_time1All)[1])`
participants for the role of advisees in Stage 1 of our main experiment.
To arrive at a gender-balanced sample, we dropped the last two
male participants to complete the survey, ending up with a sample of 500
men and 500 women ($M_{\text{Age}}$ = `r mean(study1_time1$Age)`). 
Participants completed the same 10-item mathematics quiz as the
earlier participants and were informed that their performance would
affect their bonus earnings in a follow-up stage to be conducted a few
days later. After completing the quiz, we informed them of the average
score of a group of five participants from the preliminary survey. We
randomly assigned them to learn about the 5<sup>th</sup> percentile of groups,
which scored `r p5`. ("Low Expectations" treatment) or the 95<sup>th</sup>
percentile of groups, which scored `r p95` ("High Expectations"
treatment). Participants then made a guess (unincentivized) about how
many questions they think they answered correctly. The survey concluded
with basic demographic questions.

We then recruited `r scales::comma(dim(study1_time2_giver)[1])`
participants for Stage 2, placing them in the role of advisers. We began
by informing them of the mathematics quiz that participants in the
preliminary study and Stage 1 had completed, and informed them of the
average score of all participants in the preliminary study. Advisers had to recommend
whether an advisee should compete against the Low Performers or the High
Performers (we used these terms in the survey). We anticipated that
being told to compete against High Performers is more flattering and hence being
told to compete against the Low Performers would be disappointing if one had
expected to do well.
Advisees would earn 30 cents if their score was equal to or higher than
a randomly selected member of the Low Performer group and they chose to
compete against this group, or 50 cents if they performed as well or
better than a randomly selected member of the High Performer group and they
chose to compete against that group. If
they scored lower, they would not receive any bonus.

Advisers were randomly assigned to one of two treatments. In the
"Baseline" treatment, they only observed the score of the advisee on the
mathematics quiz. In the "Expectation" treatment, they observed the
score as well as the advisee's guess for how many questions they
answered correctly. Note that since the outcome is determined only by
the past score on the quiz, the advisee's guess is immaterial to which
group they should compete against. Moreover, in neither treatment did they
receive any demographic information about their advisee. Participants
gave recommendations to 10 advisees, which unbeknownst to them were five
men and five women matched to have identical performance on the test.^[We made this decision to account for the possibility of gender differences in performance.]
They were informed that if their advice was shown to a participant who
returned for the follow-up survey, they would receive the identical
bonus as that participant. The survey then concluded with basic
demographic questions. 

Finally, we invited participants from Stage 1
back for the follow-up survey. Following our preregistration, we kept
the survey open for 7 days. In total,
`r scales::comma(dim(study1_time3)[1])` participants
(`r scales::comma(dim(study1_time3[study1_time3$Gender == 'Male',])[1])`
men,
`r scales::comma(dim(study1_time3[study1_time3$Gender == 'Female',])[1])`
women) returned. The brief survey reminded them of the task they
completed in Stage 1, informed them that other participants from
Prolific had observed their real score and given them advice against
which group to compete against, and finally were reminded them of how many
questions they guessed they had answered correctly. Importantly, they
were not informed of their true score or the score of the groups they
could compete against. Participants then observed the advice from a
randomly selected adviser and made their decision.

```{r}
library("papaja")
# Fit linear regression model
study1_advice <- study1_advice %>% dplyr::mutate(ExpShow = ifelse(Condition == 'E',1,0))

model1 <- lm(Guess ~ Gender + count, data = study1_time1)
model1_apa <- apa_print(model1)
```

## Results

We begin by examining the performance of the Stage 1 participants.
Because our treatment takes place after participants completed the
mathematics quiz, we would not expect a difference in performance across
the Low and High Expectations treatments. Indeed, the two groups scored
no different from one another
(`r round(mean(study1_time1[study1_time1$Condition == "Low",]$count),2)`
and
`r round(mean(study1_time1[study1_time1$Condition == "High",]$count),2)`
for the Low Expectations and High Expectations treatments, respectively,
`r papaja::apa_print(t.test(count ~ Condition, data = study1_time1, var.equal = T))$statistic`).
The expectations treatment did, however, affect how well they thought
they performed. Participants in the "Low Expectations" treatment guessed
a score of
`r round(mean(study1_time1[study1_time1$Condition == "Low",]$count),2)`
vs.
`r round(mean(study1_time1[study1_time1$Condition == "High",]$Guess),2)`
in the High Expectations treatment
(`r papaja::apa_print(t.test(Guess ~ Condition, data = study1_time1, var.equal = T))$statistic`),
showing that the manipulation was successful, albeit small. Contrary to our
expectations, we did find a gender difference in performance: men scored
`r round(mean(study1_time1[study1_time1$Gender == "Male",]$count),2)` on
average, while women scored
`r round(mean(study1_time1[study1_time1$Gender == "Female",]$count),2)`
(`r papaja::apa_print(t.test(count ~ Gender, data = study1_time1, var.equal = T))$statistic`).
Consistent with this difference, men thought they answered more questions 
correctly than did
women
(`r round(mean(study1_time1[study1_time1$Gender == "Male",]$Guess),2)`
vs
`r round(mean(study1_time1[study1_time1$Gender == "Female",]$Guess),2)`,
`r papaja::apa_print(t.test(Guess ~ Gender, data = study1_time1, var.equal = T))$statistic`).
This difference, however, does not affect the interpretation of our
findings, which will rely on an interaction of gender with an
experimental treatment for Stage 2 participants.

We define a measure of "overconfidence" as (Performance - Estimate). We observe
that women underestimate their performance by 0.76 points, while men do so by
only 0.27 points `r papaja::apa_print(t.test(overconfidence ~ Gender, data = study1_time1 %>% dplyr::mutate(overconfidence = Guess - count)))$full_result`.
Although neither gender is overconfident, men on average are more confident in
their performance than are women, as we had expected.

```{r study1regs}
study1_advice <- study1_advice %>% dplyr::mutate(Treatment = factor(Treatment, levels = c('Low', 'High')))

# David: No need to redefine a factor variable as a continuous number. Easier to just change the reference level.

modelsummary::modelsummary(list(`(1)` = lm(Advice ~ Treatment + Performance , data = study1_advice %>% dplyr::filter(ExpShow == 1)),
                                `(2)` = lm(Advice ~ ExpShow*Gender , data = study1_advice),
                                `(3)` = lm(ExpectedBonus ~ ExpShow*Gender, data = study1_advice)),
                           vcov = c(~GiverID, ~GiverID,~GiverID),
                            coef_map = c("TreatmentHigh" = "High Expectation",
                                         "Performance" = "Performance",
                                         "ExpShow" = "Expectation Shown",
                                        "GenderMale" = "Advisee Male",
                                        "ExpShow:GenderMale" = "Expectation x Male",
                                        "(Intercept)" = "Constant"),
                           stars = T,
                           gof_map = list(list('raw' = 'nobs', 'clean' = 'N', 'fmt' = 0)),
                           caption = "Column 1 displays the advice given to compete against a High Performance group based on whether the advisees were primed with low or high expectations and the expectation level shown to the advisor. Column 2 displays the advice given to compete against a High Performance group based on the gender of the targets and the expectation level shown to the advisor. Column 3 displays the expected bonus of the advice received based on the gender of the targets and the expectation level shown to the advisor. All standard errors clustered at the level of the advisor.")

```

```{r study1genderdiff, fig.cap ="Advisers observed real performance and the participants' estimated performance, but not their gender. As a result of their higher expectations, men (blue) were advised to compete against the high performance group more often than women (red). The grey line shows advice absent expectations, which did not differ by gender."}
library(dplyr)
library(ggplot2)
library(magrittr)

ProbHG <- study1_advice %>%
  group_by(Condition, Performance, Gender) %>%
  dplyr::summarize(avg_hardGroup = mean(Advice))


df_exp <- subset(ProbHG, Condition == "E")
df_none <- subset(ProbHG, Condition == "None")

ggplot(df_exp, aes(x = Performance, y = avg_hardGroup, color = Gender)) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"),se = FALSE) +
  geom_smooth(data = df_none, aes(x = Performance, y = avg_hardGroup),
              method = "glm", method.args = list(family = "binomial"), color = "grey", se = FALSE) +
  scale_color_manual(values = c("red", "#4169E1", "grey"),
                     labels = c("Female + Expectations", "Male + Expectations", "Expectation Hidden")) +
  scale_y_continuous(name = "P(Compete Against High Performance)",
                     labels = scales::percent,
                     expand = c(0, 0)) +
  scale_x_continuous(name = "Performance",
                     expand = c(0, 0),
                     breaks = seq(0, 10, 2)) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(colour = "grey"),
        legend.position = "bottom",
        legend.title = element_blank(),
        legend.key.size = unit(1.2, "lines"),
        legend.text = element_text(size = 12),
        plot.title = element_text(hjust = 0.5, size = 20))
```

Next, we examine whether advisers took the advisee's expectations into
account. Column 1 of Table \@ref(tab:study1regs) reports a linear
probability model on advising to compete against the High Performer
group for advisers in the "Expectations" treatment, controlling for the
true performance of the advisee. Because each adviser
made ten recommendations, we cluster standard errors at the adviser
level. However, contrary to our expectations, we do not see a significant
effect of the expectations treatment. This may be because the induced difference
in expectations was too small.

However, recall that men were more confident in their performance than were women.
Our theory thus predicts that showing expectations should lead to more flattering
advice (i.e., a recommendation to compete against the High Performer group) for
men than for women. We report a linear probability model with advice to
compete against the high group as the outcome measure, and the advisee's
gender, whether expectations were shown to the adviser, and the
interaction of the two in Column 2 of Table \@ref(tab:study1regs). As
predicted, we find a significant interaction effect: men are more likely
to be advised to compete against the High Performers when expectations
are shown than when they are hidden ($p < 0.001$).
We show this result graphically in Figure \@ref(fig:study1genderdiff)). <!-- Amanda: The gender discrepancy in advice is more significant when performance is less decisive. When performance is extremely low, there is no chance to win high performers and only a slim chance when competing with low performers. When performance is extremely high, it makes no sense to forgo the high chance to win more and choose a low bonus. However, in the middle range of performance, either option has pros and cons, and neither is absolutely better. In such a situation, advisers would take participants' expectations into account, regarding them as a critical factor. -->


To examine the quality of advice, we computed the expected bonus
earnings for someone who followed the recommendations. For example, if an
adviser suggested competing against the High Performer group, we matched the
advisee against all 20 members of that group and determined how often their score
matched or exceeded that of the member. We then multiplied this number by the
respective bonus earnings (50 cents and 30 cents for the High and Low Performer 
group, respectively). To see if including expectations leads to worse advise
for men, we report a linear probability model with the experimental treatment
of the adviser, the gender of the advisee, and their interaction in Column 3
of Table \@ref(tab:study1regs). Displaying expectations led men to be advised
to compete against the High Performer group more often, and this advise turned
out to be bad: men receive worse advise than do women when expectations are 
displayed, but not in their absence.^[This analysis was not preregistered, and we note here that the reduction in expected earnings is small. However, it is interesting that expectations have a negative effect for men who underestimate their performance on average. One possibility is that advisers suggest the High Performer group more often than is optimal. We return to the possibility that advice is overall biased to be flattering in Study 2.]

```{r study1time3}

study1_time3 <- study1_time3 %>% dplyr::mutate(AdviseeCondition = factor(AdviseeCondition, levels = c('Low', 'High'))) %>%
     dplyr::mutate(Adopt = ifelse(Bet == Advice,1,0))

modelsummary::modelsummary(list(`(1)` = lm(bonus ~ AdviseeCondition + AdviseeScore , data = study1_time3),
                                `(2)` = lm(Bet ~ Gender + AdviseeScore , data = study1_time3),
                                `(3)` = lm(Adopt ~ Gender + GiverCondition + Advice, data = study1_time3),
                                `(4)` = lm(Adopt ~ Gender + GiverCondition + Advice + Gender*GiverCondition + GiverCondition*Advice + Gender*Advice, data = study1_time3)),
                           vcov = c("classical", "classical","classical","classical"),
                            coef_map = c("AdviseeScore" = "Performance",
                                         "AdviseeConditionHigh" = "High Expectation",
                                        "GenderMale" = "Advisee Male",
                                        "GenderMale:GiverCondition" = "Expectation x Male",
                                        "GiverCondition" = "Expectation Shown",
                                        "Advice1" = "Advice: High Performer",
                                        "GenderMale:Advice1" = "Advice: High Performer x Male",
                                        "GiverCondition:Advice1" = "Expectation x Advice: High Performer",
                                        "(Intercept)" = "Constant"),
                           stars = T,
                           gof_map = list(list('raw' = 'nobs', 'clean' = 'N', 'fmt' = 0)),
                           caption = "Column 1 displays the actual bonus based on the performance and whether the participant is primed with high expectations. Column 2 displays whether the participant chooses to compete against a high-performance group based on performance and gender of the participants. Columns 3 and 4 display the chance of adopting the advice based on the gender of the participants, whether the advisee sees expectations, and whether the advice is to compete against high performers. The former considers only the main effect, while the latter also includes the interactive effect.")

```

To determine whether flattering advice is truly costly, however, we need
to examine the outcome of the advisees. In particular, they could ignore flattering
advice, recognizing it as such and thus failing to adhere to it.

<!-- David: Let's turn the regression you discussed below into a column of the Table above --> 
<!-- Amanda: Can we create a new table for analyzing time 3 data? Because the variables are different from the previous table, the current table might be difficult to read with new columns. Additionally, the new analysis is only focused on fr advice shown to its target, not all 10,000 advice. It might be vonfusing if we put them together. --> 
<!-- David: Also, one more suggestion for an analysis: let's look at whether Advisees followed the recommendation they received as an other linear probability model (1/0). I would suggest predictors of whether it's the High Performer group, whether the adviser saw expectations, the gender of the advisee. Also, another model that has the two-way interaction for all of those. We may not end up reporting this, but I would be curious to see. -->


## Discussion
When the quality of a decision is not dependent on someone's expectations,
advice should not be moved by whether an adviser is aware of the advisees
expectations. However, consistent with our account that advisers consider the
belief utility of the advisee and want to flatter, rather than disappoint them,
we find that displaying expectations to advisers does matter.
Specifically, we found that men underestimate their score on a mathematics test
less than do women. When these expectations are displayed to advisers, they
are more likely to tell men to compete against the High Performer group.
Notably, this is bad advice: men whose advisers observed their expectations
got worse advice as a result.

<!-- David: One more sentence about the earnings difference here, which does not -->
<!-- differ significantly. And one sentence about the new analysis of whether -->
<!-- people follow the advice or not. -->

# Study 2

<!-- David: Just commenting on what I tried to do here... a bit of a transition -->
<!-- for why this study follows from the last. -->
So far, we have shown that displaying expectations can induce gender
differences in advice-giving. Specifically, advisers were more likely to
recommend competing against a group of High Performers to men who had higher
expectations about their performance than did women. We now test directly whether this 
is driven by interpersonal concerns. Specifically, we examine whether 
more flattering advice is the result of a desire to be liked and whether
advisees indeed do like advisers more when they give flattering advice.

We conducted a three-stage experiment in which we experimentally manipulated
the incentives for advicers. We began by inviting a group of advisees to upload 
photos of themselves ("selfies") and informed them that they would be rated
on their attractiveness. We grouped them with nine other participants of the
same gender and recruited participants of the opposing gender to rank them from
most to least attractive and to provide advice. Specifically, we asked them
to advise the participant they ranked as the 7th most attractive (4th least attractive)
on what rank they should bet they were ranked by a larger group of raters.
Advisers were randomly assigned to two treatments, receiving a bonus payment
either if the advisee guessed their rank accurately or if the advisee evaluated
the adviser as likeable as measured by an unincentivized scale response.
We hypothesize that advisers who want to be liked by advisees will recommend 
that they bet on a lower rank, i.e. that they are more attractive.

```{r}

study2_time1 <- readRDS(here::here("Data/Study2_time1.Rds"))
study2_time1_200 <- readRDS(here::here("Data/Study2_time1_200.Rds"))
study2_time2 <- readRDS(here::here("Data/Study2_time2.Rds"))
study2_time3 <- readRDS(here::here("Data/Study2_time3.Rds"))

```

## Methods

We recruited 300 participants from Prolific and invited them to upload photos of
themselves (selfies) to be rated by other participants on
attractiveness.
`r scales::comma(dim(study2_time1[study2_time1$gender == 'Male',])[1])`
men and
`r scales::comma(dim(study2_time1[study2_time1$gender == 'Female',])[1])`
women agreed to do so and uploaded pictures that adhered to our
instructions (e.g., did not include other people). We selected the
first 100 photos from women to arrive at a gender-balanced sample
($M_{\text{Age}}$ = `r mean(study2_time1_200$age)` years).
Participants were informed that their selfies would be randomly grouped with
those of nine other participants of their gender and ranked in terms of attractiveness
by a group of new Prolific participants of the opposite gender.
They then guessed their rank (unincentivized) and the survey concluded
with demographic questions **David: or did we start with those?**

Next, we recruited a new, gender-balanced sample for the role
of advisers. `r scales::comma(dim(study2_time2)[1])`
participants from Prolific ($M_{\text{Age}}$ =
`r mean(study2_time2$age)` years;
`r round(mean(study2_time2$gender == "Female")*100, 2)`% Female) started by
providing demographic information, then were matched to a group of the opposite
gender. They then ranked participants from most to least attractive using a
drop-down menu next to each picture.
<!-- David: wasn't there something with participants selecting the same rank more -->
<!-- than once, and we dropped people who did that? Or were we able to solve this -->
<!-- and it happened only during a pilot? -->
After submitting their ratings, they saw the photo of the participant they
had ranked as the 7th most attractive (i.e., the 4th least attractive). They
were reminded of the rank they had given to that perso and informed
that this participant would be invited back and could earn a \$1 bonus if they
guessed their rank correctly. The rank was determined by the aggregate ratings
of all participants who had ranked this group. Their task was to give advice
to this participant about the rank they should bet on based on having observed
all ten selfies and their own assessment. We randomly assigned participants to
one of two incentivization schemes. In the "Accuracy" treatment, they received
a bonus identical to the advisee: \$1 if they guessed their rank correctly.
In the "Likeability" treatment, we informed them that they would be rated by
the advisee on a 5-point Likert scale for how likeable they thought they were.
Each point on the scale would translate to a bonus of 20 cents. They then
selected a rank that they would recommend the advisee to bet on.

Finally, we invited participants from Stage 1 and were ranked as the 7th
attractive by at least one adviser (so that they received advice) back
for the follow-up survey. Following our preregistration, we kept the
survey open for 7 days. In total,
`r scales::comma(dim(study2_time3)[1])` participants
(`r scales::comma(dim(study2_time3[study2_time3$gender == 'Male',])[1])`
men,
`r scales::comma(dim(study2_time3[study2_time3$gender == 'Female',])[1])`
women) returned. They were reminded of the selfie they uploaded in Stage
1 and informed that a group of 10 selfies, including theirs, had been
rated by other participants from Prolific. They then saw the advice from a 
randomly selected adviser and made their estimate with a \$1 incentive for
guessing accurately. They then saw the rank they had been advised to bet on
one more time and were asked
to rate the adviser's likability, warmth, friendliness,
good-naturedness, trustworthiness, and sincerity on 5-point Likert scales
(adapted from @Fiske2007).

## Results

<!-- David: The treatment differences here are hard to see. The most salient feature -->
<!-- is the spike at 7th (which suggests no flattering advice), and the spike at 5. -->
<!-- Can we try a violin plot for the advised rank?  And maybe we can add a -->
<!-- dotted horizontal line at 7. This is would be consistent with what they said -->
<!-- just on the previous screen. So a good reference line. -->

```{r study2advice, fig.cap="Advice given to the 7th most attractive participants"}
library(dplyr)
library(ggplot2)

count <- study2_time2 %>%
  group_by(Condition) %>%
  summarize(number = dplyr::n()) 

advice_avg <- study2_time2 %>%
  group_by(Condition, Advice) %>%
  summarize(n = dplyr::n()) %>%
  dplyr::mutate(conditionCount = ifelse(Condition == 'Likable',count[count$Condition == 'Likable',]$number,count[count$Condition == 'Accurate',]$number)) %>%
  dplyr::mutate(percent = n/conditionCount*100) %>% 
  dplyr::select(Condition,Advice,percent)
  

# Create a facet plot with condition as the facet variable and gender as the line color
ggplot(advice_avg, aes(x = Advice, y = percent, color = Condition)) +
  geom_line(linewidth = 0.75)+
  scale_color_manual(values = c("#FFA500", "#4169E1"),
                      labels = c("Accurate", "Likable")) +
  scale_y_continuous(name = "% of participants") +
  scale_x_continuous(name = "Advised Rank",
                     breaks = seq(1, 10)) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(colour = "grey"),
        legend.position = "bottom",
        legend.title = element_blank(),
        legend.key.size = unit(1.2, "lines"),          
        legend.text = element_text(size = 12),
        plot.title = element_text(hjust = 0.5, size = 20))

```

We begin by examining the prior beliefs of advisees who uploaded their selfies.
On average, men guessed they ranked `r round(mean(study2_time1[study2_time1$gender == "Male",]$Guess),2)` in their group of 10 and women guessed that they ranked
`r round(mean(study2_time1[study2_time1$gender == "Female",]$Guess),2)`.
Participants overall underestimate their attractiveness relative to the benchmark
average of 5.5. Moreover, women do so more than men
`r papaja::apa_print(t.test(Guess ~ gender, data = study2_time1, var.equal = T))$statistic`.
Notably, people's self-perceptions correlated strongly/weakly with the aggregate
ratings of the advisers (correlation coefficient & cor.test). However, there
was substantial heterogeneity in perceptions of attractiveness.
Of the 200 participants, XXX were ranked as 7th most attractive by at least one
adviser. On average,
men in this subset estimated they were ranked Xth and women estimated they were
ranked Xth (t-test).

<!-- David: Some stats to fill in above. I think this would be interesting to include -->
<!-- even though we don't make any predictions about this. -->

Next, we turn our attention to the advisers (Figure \@ref(fig:study2advice)). 
In the Accuracy condition, those
uploading selfies were advised to bet on rank `r round(mean(study2_time2[study2_time2$Condition == "Accurate",]$Advice),2)`.
Notably, this is significantly more attractive than the 7th rank those advisers
had themselves guessed just on the prior screen
(`r papaja::apa_print(t.test(study2_time2[study2_time2$Condition == "Accurate",]$Advice, mu = 7, var.equal = T))$statistic`).
This suggests that even when incentivized for accuracy, participants offered
flattering advice.^[This shading could be due to concerns of avoiding disappointment. However, it could also be that advisers are uncertain about the rankings they had given and make a recommendation that combines their own belief with a uniform prior.]
Importantly, and as predicted, we find that advisers in the Likeable treatment
recommend betting on a lower rank, communicating that they think the participant
in the selfie is more attractive
(`r round(mean(study2_time2[study2_time2$Condition == "Likable",]$Advice),2)`,
`r papaja::apa_print(t.test(Advice ~ Condition, data = study2_time2, var.equal = T))$statistic`).
This suggests that advisers inferred that advising someone that they
were more attractive would make the adviser appear more likeable and
therefore provided advice that communicated a more favorable impression
of the participants' attractiveness. The distribution shown in Figure \@ref(fig:study2advice)
shows that participants do not simply tell participants that they are the
most attractive person in the group. They may infer that flattering advise needs
to be somewhat realistic to be believable. We return to this in the general discussion.

<!-- David: Making a note here that we should be sure to discuss this at the end -->
<!-- as something for future research. -->

```{r study2regs}

modelsummary::modelsummary(list(`(1)` = lm(likable ~ Advice, data = study2_time3),
                                `(2)` = lm(warmAvg ~ Advice, data = study2_time3),
                                `(3)` = lm(trustAvg ~ Advice, data = study2_time3)),
                           vcov = c("classical", "classical", "classical"),
                           coef_map = c("Advice" = "Advised Rank",
                                        "(Intercept)" = "Constant"),
                           stars = T,
                           gof_map = list(list('raw' = 'nobs', 'clean' = 'N', 'fmt' = 0)),
                           caption = "When individuals receive advice that implies a high level of attractiveness (lower rank), they tend to perceive the advice giver as more likable (Column 1), warm (Column 2). Column 3 shows that advisors are rated as more trustworthy when they advice lower ranks, but this relationship is only directional.")

```

```{r study2rating, fig.cap="The evaluation of advice givers"}

rating <- study2_time3 %>%
  group_by(Advice) %>%
  summarise(Likable = mean(likable), Warm = mean(warmAvg), Trust = mean(trustAvg))

ggplot(rating, aes(x = Advice)) +
  geom_line(aes(y = Likable, color = "Likable"), linewidth = 0.75) +
  geom_line(aes(y = Warm, color = "Warm"), linewidth = 0.75) +
  geom_line(aes(y = Trust, color = "Trust"), linewidth = 0.75) +
  scale_color_manual(values = c("Likable" = "#FFA500", "Warm" = "#4169E1", "Trust" = "grey"),
                      labels = c("Likable", "Warm", "Trust")) +
  scale_y_continuous(name = "Rating") +
  scale_x_continuous(name = "Advised Rank") +
  theme_bw() +
  theme(panel.grid = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(colour = "grey"),
        legend.position = "bottom",
        legend.title = element_blank(),
        legend.key.size = unit(1.2, "lines"),          
        legend.text = element_text(size = 12),
        plot.title = element_text(hjust = 0.5, size = 20))


```

Finally, we examine whether flattering advice indeed leads to more positive evaluations of
advisers, or whether flattering advice is dismissed as insencere.
Following our preregistration, we average the ratings on likeability,
warmth,  friendliness, and good-naturedness to create a scale of likeability
($\alpha$ = XXX);
<!-- David: The draft had trustworthiness as part of this scale. -->
<!-- Can we just double-check against the preregistration? -->
<!-- And was Likeable part of that? -->
<!-- We might also want a name for the scale that isn't the same as one -->
<!-- of the items, though I'm not sure what. -->
<!-- Same for trustworthiness -- though that could simply be "Trust" -->
and we create a scale of trustworthiness by averaging the ratings of
trustworthiness and sincerity ($\alpha$ = XXX).

<!-- The Figure is not super clear. How about we try a series of box plots, -->
<!-- with the x-axis as the advised rank? Standard errors will be huge at the -->
<!-- extremes. -->

<!-- Also, we need to do something relative to the advisees' expectations. -->
<!-- I wonder what would be interesting here? Maybe averages for three groups: -->
<!-- more attractive than the participants' own guess, equally attractive, and less -->
<!-- attractive? -->

As seen in Figure \@ref(fig:study2rating), we
found that advisees who suggested that the advisee was more attractive
(lower rank) were indeed rated as more likeable and warm (b = -0.109, p
\< .05; b = -0.133, p \< .001, respectively; See Columns 1 and 2 of Table \@ref(tab:study2regs)).
Interestingly, these benefits are not at the cost of being hypocritical;
advisers who recommend a more favorable rank are viewed as no less trustworthy
(Column 3 of Table \@ref(tab:study2regs)). 

We were not powered to do a comparison across the two 
experimental groups and did not preregister such a difference.
<!-- David: But we still need to report warmth & trust across treatments. -->

## Discussion


# General Discussion

Advice substantially shapes people's career and personal outcomes.
Therefore, understanding advisers' motivations has far-reaching
implications. We propose that advisers' focus on advisees' expectations
and the desire to avoid disappointing them can induce gender differences
in the advice given and ultimately in the outcomes achieved. Gender
differences in career outcomes contribute significantly to the gender
wage gap, with women often holding less senior positions and
experiencing worse career outcomes, even with equal performance.
Therefore, identifying a factor such as expectations that contributes to
this gap has important implications for organizational practice.

In this paper, we examine a novel and unexplored factor of
advice-giving: interpersonal considerations. Advisers who take into
account the advisee's belief utility inflate their advice to convey a
more favorable impression, leading to worse decisions and gender
differences. Men have more inflated expectations than women, and taking
expectations into account can lead to gender differences, even without
discrimination. We ruled out discrimination as a separate channel by
withholding information about the gender of the advisee. Finally, we
expect that advisers are aware of the tradeoff between giving accurate
advice and avoiding disappointment and, thus, are less likely to inflate
their advice when advisees can compensate them after observing the
outcome of their choice.

The findings of this study suggest that organizations can promote gender
equity by calibrating employees' expectations or shifting advisers'
attention away from them. While these measures may not entirely solve
the gender gap problem, they can make a meaningful difference when
unconscious bias interventions have failed to show any effect
[@Chang2019; @Paluck2009]. We believe our findings may be particularly
relevant to societies that value signaling in interpersonal
relationships. Future work
could also examine whether people in different cultures place more
weight on expectations.

# References

```{=tex}
\begingroup
\singlespacing
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\noindent
```
::: {#refs}
:::

```{=tex}
\endgroup
```
